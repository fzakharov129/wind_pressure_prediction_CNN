{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12077457,"sourceType":"datasetVersion","datasetId":7602622}],"dockerImageVersionId":31041,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":4800.720152,"end_time":"2025-05-29T03:01:48.764113","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-29T01:41:48.043961","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# üì¶ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\nimport os\nimport json\nimport random\n\n# üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.ticker as ticker\n\n# ü§ñ –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n# üî• PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n\n# ‚è≥ –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä\nfrom tqdm import tqdm\n","metadata":{"papermill":{"duration":8.821196,"end_time":"2025-05-29T01:42:01.778418","exception":false,"start_time":"2025-05-29T01:41:52.957222","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T01:09:13.679873Z","iopub.execute_input":"2025-06-09T01:09:13.680216Z","iopub.status.idle":"2025-06-09T01:09:13.684831Z","shell.execute_reply.started":"2025-06-09T01:09:13.680197Z","shell.execute_reply":"2025-06-09T01:09:13.684155Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# ----------------------------\n# Device setup\n# ----------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"üõ† Device: {device}\")\n\n# ----------------------------\n# Paths setup\n# ----------------------------\n# DATA_PATH = \"/kaggle/input/wind-pressure-prediction-cnn-train\"\nSAVE_ROOT = \"/kaggle/working\"\n\n# SAVE_ROOT = \"/mnt/d/projects/wind_pressure_prediction_CNN/experiments\"\n# DATA_ROOT = \"/mnt/d/projects/wind_pressure_prediction_CNN\"\n\nTUNING_DIR = os.path.join(SAVE_ROOT, \"tuning_CNN\")  \nLOG_CSV_PATH = os.path.join(SAVE_ROOT, \"experiments_log.csv\")\n\nos.makedirs(TUNING_DIR, exist_ok=True)\n\n# ----------------------------\n# Function to create a run-specific directory\n# ----------------------------\ndef create_run_directory(\n    run_name=\"cnn\", lr=1e-3, batch_size=64, epochs=500,\n    activation_fn=None, optimizer_name=None, base_dir=TUNING_DIR\n):\n    run_id = f\"{run_name}_{lr:.0e}lr_{batch_size}bs_{epochs}ep\"\n    \n    if activation_fn is not None:\n        run_id += f\"_{activation_fn.__name__}\"\n    if optimizer_name is not None:\n        run_id += f\"_{optimizer_name}\"\n\n    run_dir = os.path.join(base_dir, run_id)\n    os.makedirs(run_dir, exist_ok=True)\n    print(f\"üìÇ Created run directory: {run_dir}\")\n    \n    return run_id, run_dir\n","metadata":{"papermill":{"duration":0.111946,"end_time":"2025-05-29T01:42:01.893208","exception":false,"start_time":"2025-05-29T01:42:01.781262","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T01:09:13.685951Z","iopub.execute_input":"2025-06-09T01:09:13.686234Z","iopub.status.idle":"2025-06-09T01:09:13.701797Z","shell.execute_reply.started":"2025-06-09T01:09:13.686212Z","shell.execute_reply":"2025-06-09T01:09:13.701153Z"}},"outputs":[{"name":"stdout","text":"üõ† Device: cuda\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# ‚û§ –ö–ª–∞—Å—Å CNN-–º–æ–¥–µ–ª–∏\nclass WindPressureCNN(nn.Module):\n    def __init__(self, input_channels, filters, activation_fn, use_batchnorm):\n        super(WindPressureCNN, self).__init__()\n\n        layers = []\n        in_channels = input_channels\n        for out_channels in filters:\n            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n            if use_batchnorm:\n                layers.append(nn.BatchNorm2d(out_channels))\n            layers.append(activation_fn())\n            in_channels = out_channels\n\n        self.encoder = nn.Sequential(*layers)\n\n        self.decoder = nn.Sequential(\n            nn.Conv2d(filters[-1], filters[-2], kernel_size=3, padding=1),\n            activation_fn(),\n            nn.Conv2d(filters[-2], 1, kernel_size=1)\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n","metadata":{"papermill":{"duration":0.008519,"end_time":"2025-05-29T01:42:01.925496","exception":false,"start_time":"2025-05-29T01:42:01.916977","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T01:09:13.727325Z","iopub.execute_input":"2025-06-09T01:09:13.727538Z","iopub.status.idle":"2025-06-09T01:09:13.733980Z","shell.execute_reply.started":"2025-06-09T01:09:13.727522Z","shell.execute_reply":"2025-06-09T01:09:13.733289Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# ‚û§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π Dataset\nclass WindGridDataset(Dataset):\n    def __init__(self, X_tensor, Y_tensor):\n        self.X = X_tensor\n        self.Y = Y_tensor\n\n    def __len__(self):\n        return self.X.shape[0]\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.Y[idx]\n\n# ‚û§ –û—Ü–µ–Ω–∫–∞\ndef evaluate_regression(y_true, y_pred):\n    y_true = y_true.detach().cpu().numpy().reshape(-1)\n    y_pred = y_pred.detach().cpu().numpy().reshape(-1)\n    mask = ~np.isnan(y_true) & ~np.isnan(y_pred)\n    return {\n        \"MSE\": mean_squared_error(y_true[mask], y_pred[mask]),\n        \"MAE\": mean_absolute_error(y_true[mask], y_pred[mask]),\n        \"R2\": r2_score(y_true[mask], y_pred[mask])\n    }\n\n# ‚û§ –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è\ndef train_cnn(\n    lr,\n    batch_size,\n    epochs,\n    input_channels,\n    activation_fn,\n    optimizer_name,\n    loss_fn,\n    filters,\n    use_batchnorm\n    ):\n    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n    '''\n    X_all = np.load(os.path.join(\n    DATA_ROOT, \"data\", \"processed\", \"cnn_input\", \"X_cnn.npy\"\n    ))\n    Y_all = np.load(os.path.join(\n    DATA_ROOT, \"data\", \"processed\", \"cnn_input\", \"Y_cnn.npy\"\n    ))\n    '''\n\n    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ Kaggle Input\n    X_all = np.load(\"/kaggle/input/wind-pressure-prediction-cnn-train/X_cnn.npy\")\n    Y_all = np.load(\"/kaggle/input/wind-pressure-prediction-cnn-train/Y_cnn.npy\")\n\n\n    X_tensor = torch.tensor(X_all, dtype=torch.float32).to(device)\n    Y_tensor = torch.tensor(Y_all, dtype=torch.float32).to(device)\n    print(\"X_all shape:\", X_all.shape)\n    print(\"Y_all shape:\", Y_all.shape)\n\n    n_splits = 5\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n    fold_metrics = []\n\n    for fold, (train_idx, val_idx) in enumerate(kf.split(X_tensor)):\n        print(f\"\\nüîÅ Fold {fold + 1} / {n_splits}\")\n\n        model = WindPressureCNN(\n            input_channels=input_channels,\n            filters=filters,\n            activation_fn=activation_fn,\n            use_batchnorm=use_batchnorm\n        ).to(device)\n\n        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å\n        criterion = loss_fn()\n\n        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä\n        if optimizer_name == \"Adam\":\n            optimizer = optim.Adam(model.parameters(), lr=lr)\n        elif optimizer_name == \"SGD\":\n            optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n        else:\n            raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n\n        # –î–∞—Ç–∞—Å–µ—Ç—ã –∏ –∑–∞–≥—Ä—É–∑—á–∏–∫–∏\n        train_dataset = WindGridDataset(X_tensor[train_idx], Y_tensor[train_idx])\n        val_dataset   = WindGridDataset(X_tensor[val_idx],   Y_tensor[val_idx])\n        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n        val_loader   = DataLoader(val_dataset, batch_size=batch_size)\n\n        best_loss = float(\"inf\")\n        patience = 100\n        counter = 0\n\n        for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n            model.train()\n            epoch_loss = 0.0\n            for batch_X, batch_Y in train_loader:\n                optimizer.zero_grad()\n                outputs = model(batch_X)\n                loss = criterion(outputs, batch_Y)\n                loss.backward()\n                optimizer.step()\n                epoch_loss += loss.item()\n\n            # ‚û§ –û—Ü–µ–Ω–∏–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞–∂–¥—ã–µ 20 —ç–ø–æ—Ö\n            if (epoch + 1) % 100 == 0 or epoch == 0 or epoch == epochs - 1:\n                model.eval()\n                with torch.no_grad():\n                    y_val_pred = model(X_tensor[val_idx])\n                    epoch_metrics = evaluate_regression(Y_tensor[val_idx], y_val_pred)\n                    print(f\"üìâ Epoch {epoch + 1} | Train Loss: {epoch_loss:.6f} | \"\n                        f\"Val R2: {epoch_metrics['R2']:.4f} | \"\n                        f\"MAE: {epoch_metrics['MAE']:.4f} | \"\n                        f\"MSE: {epoch_metrics['MSE']:.6f}\")\n\n\n            # Early stopping\n            val_loss = 0.0\n            model.eval()\n            with torch.no_grad():\n                for batch_X, batch_Y in val_loader:\n                    outputs = model(batch_X)\n                    loss = criterion(outputs, batch_Y)\n                    val_loss += loss.item()\n\n            if val_loss < best_loss:\n                best_loss = val_loss\n                counter = 0\n            else:\n                counter += 1\n                if counter >= patience:\n                    print(\"‚èπÔ∏è Early stopping\")\n                    break\n\n        # ‚û§ –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n        model.eval()\n        with torch.no_grad():\n            y_pred = model(X_tensor[val_idx])\n            metrics = evaluate_regression(Y_tensor[val_idx], y_pred)\n            fold_metrics.append(metrics)\n            print(f\"üìà Fold {fold + 1} metrics:\", metrics)\n\n    # ‚û§ –°—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏\n    avg_metrics = {\n        \"MSE\": np.mean([m[\"MSE\"] for m in fold_metrics]),\n        \"MAE\": np.mean([m[\"MAE\"] for m in fold_metrics]),\n        \"R2\":  np.mean([m[\"R2\"]  for m in fold_metrics]),\n    }\n\n    # ‚û§ –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥ –∏ –ª–æ–≥\n    run_id, run_dir = create_run_directory(run_name=\"cnn\", lr=lr, batch_size=batch_size, epochs=epochs)\n    config = {\n    \"model\": \"CNN\",\n    \"lr\": lr,\n    \"batch_size\": batch_size,\n    \"epochs\": epochs,\n    \"input_channels\": input_channels,\n    \"activation_fn\": activation_fn.__name__,\n    \"optimizer\": optimizer_name,\n    \"loss_fn\": loss_fn.__name__,\n    \"filters\": filters,\n    \"batchnorm\": use_batchnorm,\n    \"target_shape\": \"1x9x28\"\n    }\n\n    # ‚û§ –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n    BEST_MODEL_DIR = os.path.join(SAVE_ROOT, \"best_model\")\n    os.makedirs(BEST_MODEL_DIR, exist_ok=True)  # —Å–æ–∑–¥–∞—ë–º, –µ—Å–ª–∏ –Ω–µ—Ç\n\n    # ‚û§ –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤–µ—Å–æ–≤\n    MODEL_SAVE_PATH = os.path.join(BEST_MODEL_DIR, f\"best_{run_id}.pth\")\n\n    # ‚û§ –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏, –µ—Å–ª–∏ R¬≤ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞\n    if avg_metrics[\"R2\"] > 0.2:\n        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n        print(f\"üíæ Saved best model weights to {MODEL_SAVE_PATH}\")\n\n\n    with open(os.path.join(run_dir, f\"config_{run_id}.json\"), \"w\") as f:\n        json.dump(config, f, indent=4)\n\n    log_header = \"run_id,model,lr,batch_size,activation_fn,optimizer,filters,R2,MAE,MSE\\n\"\n\n    log_line = (\n    f\"{run_id},cnn,{lr:.0e},{batch_size},\"\n    f\"{activation_fn.__name__},{optimizer_name},\"\n    f\"\\\"{filters}\\\",\"  # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –∫–∞–∫ —Å—Ç—Ä–æ–∫—É\n    f\"{float(avg_metrics['R2']):.4f},\"\n    f\"{float(avg_metrics['MAE']):.4f},\"\n    f\"{float(avg_metrics['MSE']):.6f}\\n\"\n    )\n\n\n\n    write_header = not os.path.exists(LOG_CSV_PATH)\n\n    with open(LOG_CSV_PATH, \"a\") as f:\n        if write_header:\n            f.write(log_header)\n        f.write(log_line)\n    \n\n    print(\"\\nüìä Avg Metrics across 5 folds:\", {\n    \"MSE\": float(avg_metrics[\"MSE\"]),\n    \"MAE\": float(avg_metrics[\"MAE\"]),\n    \"R2\":  float(avg_metrics[\"R2\"])\n    })\n    return run_id, avg_metrics\n","metadata":{"papermill":{"duration":0.020303,"end_time":"2025-05-29T01:42:01.948848","exception":false,"start_time":"2025-05-29T01:42:01.928545","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T01:09:13.836551Z","iopub.execute_input":"2025-06-09T01:09:13.836771Z","iopub.status.idle":"2025-06-09T01:09:13.859909Z","shell.execute_reply.started":"2025-06-09T01:09:13.836749Z","shell.execute_reply":"2025-06-09T01:09:13.859081Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# üìÅ src/train/train_cnn_random_search.py\n\n\n# ----------------------------\n# –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è Random Search\n# ----------------------------\nlr_choices = [0.0002, 0.0003]     # üîß –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (learning rate)\nbatch_size_choices = [64]                 # üì¶ –†–∞–∑–º–µ—Ä –º–∏–Ω–∏-–±–∞—Ç—á–∞\nepoch_choices = [2000]                   # üîÅ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è\n\nactivation_choices = [\n    nn.ELU,\n    nn.LeakyReLU\n    ]   \n                                               # ‚ö°Ô∏è –§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –¥–ª—è –Ω–µ–π—Ä–æ–Ω–æ–≤\noptimizer_choices = [\"Adam\"]                        # üß† –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä (–º–µ—Ç–æ–¥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–µ—Å–æ–≤)\nloss_fn_choices = [nn.MSELoss]                      # üìâ –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å (–¥–ª—è –æ—Ü–µ–Ω–∫–∏ –æ—à–∏–±–∫–∏)\n\nfilters_choices = [\n    [8, 10, 12, 14, 16, 20, 24, 28, 32, 40, 48, 56, 64, 80, 96, 128]\n]\n\n\n\n\n\n\n\nbatchnorm_choices = [True]                 # ‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ BatchNorm –ø–æ—Å–ª–µ Conv-—Å–ª–æ—ë–≤\n\n\nN_RUNS = 50  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—É—Å–∫–æ–≤\n\n# ----------------------------\n# Random Search Loop\n# ----------------------------\nfor run in range(N_RUNS):\n    lr = random.choice(lr_choices)\n    batch_size = random.choice(batch_size_choices)\n    epochs = random.choice(epoch_choices)\n    activation_fn = random.choice(activation_choices)\n    optimizer_name = random.choice(optimizer_choices)\n    loss_fn = random.choice(loss_fn_choices)\n    filters = random.choice(filters_choices)\n    use_batchnorm = random.choice(batchnorm_choices)\n\n    print(f\"\\nüîÅ Run {run + 1}/{N_RUNS}\")\n    print(f\"‚Üí lr: {lr}, batch_size: {batch_size}, epochs: {epochs}\")\n    print(f\"‚Üí activation: {activation_fn.__name__}, optimizer: {optimizer_name}, loss_fn: {loss_fn.__name__}\")\n    print(f\"‚Üí filters: {filters}, batchnorm: {use_batchnorm}\")\n\n    run_id, metrics = train_cnn(\n        lr=lr,\n        batch_size=batch_size,\n        epochs=epochs,\n        input_channels=3,\n        activation_fn=activation_fn,\n        optimizer_name=optimizer_name,\n        loss_fn=loss_fn,\n        filters=filters,\n        use_batchnorm=use_batchnorm\n    )\n\n    print(f\"‚úÖ Finished run {run_id}\")\n    print(f\"üìä Metrics: {{'MSE': {float(metrics['MSE']):.6f}, 'MAE': {float(metrics['MAE']):.6f}, 'R2': {float(metrics['R2']):.4f}}}\")\n","metadata":{"papermill":{"duration":4777.008125,"end_time":"2025-05-29T03:01:38.959230","exception":false,"start_time":"2025-05-29T01:42:01.951105","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T01:09:13.861426Z","iopub.execute_input":"2025-06-09T01:09:13.861755Z","iopub.status.idle":"2025-06-09T01:09:13.925561Z","shell.execute_reply.started":"2025-06-09T01:09:13.861729Z","shell.execute_reply":"2025-06-09T01:09:13.924557Z"}},"outputs":[{"name":"stdout","text":"\nüîÅ Run 1/50\n‚Üí lr: 0.0003, batch_size: 64, epochs: 2000\n‚Üí activation: LeakyReLU, optimizer: Adam, loss_fn: MSELoss\n‚Üí filters: [8, 10, 12, 14, 16, 20, 24, 28, 32, 40, 48, 56, 64, 80, 96, 128], batchnorm: True\nX_all shape: (608, 3, 9, 28)\nY_all shape: (608, 1, 9, 28)\n\nüîÅ Fold 1 / 5\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   0%|          | 0/2000 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([64, 1, 9, 28])) that is different to the input size (torch.Size([64, 1, 8, 28])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\nEpochs:   0%|          | 0/2000 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/4121158093.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚Üí filters: {filters}, batchnorm: {use_batchnorm}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     run_id, metrics = train_cnn(\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/2483704404.py\u001b[0m in \u001b[0;36mtrain_cnn\u001b[0;34m(lr, batch_size, epochs, input_channels, activation_fn, optimizer_name, loss_fn, filters, use_batchnorm)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction, weight)\u001b[0m\n\u001b[1;32m   3882\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3884\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (9) at non-singleton dimension 2"],"ename":"RuntimeError","evalue":"The size of tensor a (8) must match the size of tensor b (9) at non-singleton dimension 2","output_type":"error"}],"execution_count":21},{"cell_type":"code","source":"# üîÑ –ü—É—Ç—å –∫ –ª–æ–≥—É (–º–æ–∂–Ω–æ –ø–æ–º–µ–Ω—è—Ç—å –Ω–∞ –Ω—É–∂–Ω—ã–π)\n# LOG_CSV_PATH = os.path.join(DATA_ROOT, \"experiments\", \"experiments_log.csv\")\nLOG_CSV_PATH = os.path.join(SAVE_ROOT, \"experiments_log.csv\")\ndf_log = pd.read_csv(LOG_CSV_PATH)\n\n\n# üé® –°—Ç–∏–ª—å –≥—Ä–∞—Ñ–∏–∫–æ–≤\nsns.set(style=\"whitegrid\", palette=\"deep\", font_scale=1.2)\n\n# ‚û§ –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ CNN\ndf_cnn = df_log[df_log[\"run_id\"].str.startswith(\"cnn\")].copy()\nprint(f\"üìä Total CNN runs: {len(df_cnn)}\")\n\n# ------------------------------\n# üìà Boxplot: R¬≤ –ø–æ lr –∏ batch_size\n# ------------------------------\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# üìå Boxplot: Learning Rate\nsns.boxplot(x=\"lr\", y=\"R2\", data=df_cnn, ax=axes[0], width=0.6)\naxes[0].set_title(\"R¬≤ by Learning Rate\")\naxes[0].set_xlabel(\"Learning Rate\")\naxes[0].set_ylabel(\"R¬≤ Score\")\n\n# üìå Boxplot: Batch Size\nsns.boxplot(x=\"batch_size\", y=\"R2\", data=df_cnn, ax=axes[1], width=0.6)\naxes[1].set_title(\"R¬≤ by Batch Size\")\naxes[1].set_xlabel(\"Batch Size\")\naxes[1].set_ylabel(\"R¬≤ Score\")\n\nplt.tight_layout()\nplt.show()\n\n# ------------------------------\n# üî• Heatmap: R¬≤ –ø–æ lr √ó batch_size\n# ------------------------------\npivot = df_cnn.pivot_table(\n    values=\"R2\",\n    index=\"lr\",\n    columns=\"batch_size\",\n    aggfunc=\"mean\"\n).sort_index(ascending=False)\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(pivot, annot=True, fmt=\".3f\", cmap=\"YlGnBu\", linewidths=0.5, cbar_kws={\"label\": \"R¬≤ Score\"})\nplt.title(\"R¬≤ Heatmap: Learning Rate √ó Batch Size\", fontsize=16)\nplt.xlabel(\"Batch Size\")\nplt.ylabel(\"Learning Rate\")\nplt.tight_layout()\nplt.show()\n\n# ------------------------------\n# ‚≠ê –õ—É—á—à–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏\n# ------------------------------\nr2_max = df_cnn[\"R2\"].max()\nthreshold = r2_max * 0.95\nstable = df_cnn[df_cnn[\"R2\"] >= threshold]\n\nprint(f\"\\nüìå Best R¬≤: {r2_max:.4f}\")\nprint(f\"üìâ Threshold (95%): {threshold:.4f}\")\nprint(f\"üß± Stable CNN configs: {len(stable)}\\n\")\nprint(stable.sort_values(\"R2\", ascending=False)[[\"run_id\", \"lr\", \"batch_size\", \"R2\", \"MAE\", \"MSE\"]])\n","metadata":{"papermill":{"duration":3.185796,"end_time":"2025-05-29T03:01:44.040246","exception":false,"start_time":"2025-05-29T03:01:40.854450","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T01:09:13.926085Z","iopub.status.idle":"2025-06-09T01:09:13.926291Z","shell.execute_reply.started":"2025-06-09T01:09:13.926192Z","shell.execute_reply":"2025-06-09T01:09:13.926201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ‚û§ –ö–ª–∞—Å—Å CNN-–º–æ–¥–µ–ª–∏ (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –æ–Ω —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω –≤—ã—à–µ)\n# class WindPressureCNN(nn.Module): ...\n\n# üìç –£–∫–∞–∂–∏ –ø—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É –∏ –≤–µ—Å–∞–º\n#CONFIG_PATH = \"/mnt/d/projects/wind_pressure_prediction_CNN/experiments/tuning_CNN/cnn_5e-03lr_32bs_1000ep/config_cnn_5e-03lr_32bs_1000ep.json\"\n#MODEL_SAVE_PATH = \"/mnt/d/projects/wind_pressure_prediction_CNN/experiments/best_model/best_cnn_5e-03lr_32bs_1000ep.pth\"\n\n# ‚û§ –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥\nwith open(CONFIG_PATH, \"r\") as f:\n    config = json.load(f)\n\n# ‚û§ –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–º—è —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –≤ –∫–ª–∞—Å—Å\nactivation_map = {\n    \"ReLU\": nn.ReLU,\n    \"Tanh\": nn.Tanh,\n    \"Sigmoid\": nn.Sigmoid,\n    \"LeakyReLU\": nn.LeakyReLU,\n    \"ELU\": nn.ELU,\n    \"SELU\": nn.SELU,\n    \"GELU\": nn.GELU\n}\n\n\nactivation_fn = activation_map[config[\"activation_fn\"]]\n\n# ‚û§ –í–æ—Å—Å–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å\nmodel = WindPressureCNN(\n    input_channels=config[\"input_channels\"],\n    filters=config[\"filters\"],\n    activation_fn=activation_fn,\n    use_batchnorm=config[\"batchnorm\"]\n)\n\n# ‚û§ –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞\nmodel.load_state_dict(torch.load(MODEL_SAVE_PATH))\nmodel.eval()  # –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏\n\nprint(\"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.\")\n\n# ‚û§ –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º\nX_PATH = \"/mnt/d/projects/wind_pressure_prediction_CNN/data/processed/cnn_input/X_cnn.npy\"\nY_PATH = \"/mnt/d/projects/wind_pressure_prediction_CNN/data/processed/cnn_input/Y_cnn.npy\"\n\n# ‚û§ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\nX_all = np.load(X_PATH)\nY_all = np.load(Y_PATH)\n\nprint(\"üì¶ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ:\")\nprint(\"X_all:\", X_all.shape)\nprint(\"Y_all:\", Y_all.shape)\n\n# ‚û§ –í—ã–±–æ—Ä —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞\nidx = random.randint(0, len(X_all) - 1)\nX_sample = torch.tensor(X_all[idx:idx+1], dtype=torch.float32)  # shape: [1, C, H, W]\nY_true = Y_all[idx]  # shape: [1, H, W] –∏–ª–∏ [H, W]\n\n# ‚û§ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\nwith torch.no_grad():\n    Y_pred = model(X_sample).squeeze().cpu().numpy()\n\n# ‚û§ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\nfig, axs = plt.subplots(1, 2, figsize=(10, 4))\naxs[0].imshow(Y_true.squeeze(), cmap='viridis')\naxs[0].set_title(\"üéØ –ò—Å—Ç–∏–Ω–Ω–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ\")\n\naxs[1].imshow(Y_pred.squeeze(), cmap='viridis')\naxs[1].set_title(\"üîÆ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ –º–æ–¥–µ–ª—å—é\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T01:09:13.927466Z","iopub.status.idle":"2025-06-09T01:09:13.927753Z","shell.execute_reply.started":"2025-06-09T01:09:13.927590Z","shell.execute_reply":"2025-06-09T01:09:13.927606Z"}},"outputs":[],"execution_count":null}]}